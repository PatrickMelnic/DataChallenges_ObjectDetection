python clip/transformers/examples/pytorch/contrastive_image_text/run_clip.py --output_dir /clip_pretraining --model_name_or_path openai/clip-vit-base-patch32 --data_dir /CN_coin_descriptions --train_file CN_coin_descriptions/CN_hpz_dataset_reformat_train.csv --image_column "image_path" --caption_column "caption" --do_train --per_device_train_batch_size="64" --learning_rate="5e-5" --warmup_steps="0" --weight_decay 0.1 --overwrite_output_dir --push_to_hub

